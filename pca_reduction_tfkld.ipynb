{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import os, codecs\n",
    "import cPickle as pickle\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "tfkld_location = \"tfkld.pkl\"\n",
    "text_corpus_dir = \"/home/cjacques/code/gensim/extracted_wiki\"\n",
    "\n",
    "\n",
    "# Load the TFKLD Model, we'll be training the PCA Reduction on the vectors it outputs\n",
    "tfkld_model = joblib.load(tfkld_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_comments(loc):\n",
    "    for subdir, dirs, files in os.walk(loc):\n",
    "        for file in files:\n",
    "            yield os.path.join(subdir, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read through all the files in whatever directory was passed until the number of desired sentences is hit (default 20000000)\n",
    "# personally I used https://github.com/attardi/wikiextractor to get the clean text for wikipedia articles.\n",
    "def read_files_for_pca(location, num_sentences=20000000):\n",
    "    vec_list = []\n",
    "    counter = 0\n",
    "    for file_name in iter_comments(location):\n",
    "        with codecs.open(file_name, encoding='utf-8', mode=\"r\") as read_file:\n",
    "            if counter < num_sentences:\n",
    "                text = read_file.read()\n",
    "                sentences = sent_tokenize(text)\n",
    "                vec = tfkld_model.transform(sentences)[0].toarray()[0].tolist()\n",
    "                vec_list.append(vec)\n",
    "                counter += len(sentences)\n",
    "            else:\n",
    "                break\n",
    "    return np.array(vec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance = []\n",
    "\n",
    "X = np.array(read_files_for_pca(text_corpus_dir))\n",
    "pca = PCA(n_components=150)\n",
    "\n",
    "while np.sum(explained_variance) < 0.95:\n",
    "    pca.fit(X)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(np.sum(explained_variance)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec = tfkld_model.transform([\"hello world\"])[0].toarray()[0].tolist()\n",
    "new_vec = pca.transform([test_vec])\n",
    "\n",
    "print len(new_vec)\n",
    "print new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pca, \"pca_tfkld.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loading PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = joblib.load(\"pca_tfkld.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vec = tfkld_model.transform([\"hello world\"])[0].toarray()[0].tolist()\n",
    "new_vec = pca_model.transform([test_vec])\n",
    "\n",
    "print len(new_vec)\n",
    "print new_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
